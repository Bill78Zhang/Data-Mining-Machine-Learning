# Tyler Phillips
# CSCI57300 Data Mining
# Expectation Maximization (EM)

import numpy as np
import sys

# EM function
# Args:
#   D - nxd data matrix
#   mu - kxd mean matrix
#   k - cluster count
#   eps - convergence tolarence
def EM(D, k, mu, eps=0.0001):
    n, d = D.shape

    # If mu is not preset
    if np.array_equal(mu,np.zeros((k,d))):
        # Randomly intialize k means in kxd mu matrix
        mu = np.random.uniform(size=(k,d)) * np.amax(D,axis=0)

    # Intialize previous mu matrix
    prev_mu = np.zeros((k,d))

    # Intialize k covariance matricies as dxd identity matricies
    cov = [[] for i in range(k)]
    for i in range(k):
        cov[i].append(np.identity(d))

    # Intialize k cluster priors as kx1 matrix of 1./k
    priors = np.ones((k,1)) * (1./k)

    # Intialize iteration count
    iter = 1

    while True:
        # Expectation step
        w = np.zeros((k,n))
        for i in range(k):
            for j in range(n):
                denom = 0
                for a in range(k):
                    denom = denom + f(D[j,:],mu[a,:],cov[a][0]) * priors[a]
                w[i,j] = f(D[j,:],mu[i,:],cov[i][0]) * priors[i] / denom

        # Maximization step
        for i in range(k):
            # Re-estimate mu
            mu[i,:] = 0
            for j in range(n):
                mu[i,:] = mu[i,:] + w[i,j] * D[j,:] 
            mu[i,:] = mu[i,:] / np.sum(w[i,:],axis=0)

            # Re-estimate cov
            cov[i][0] = np.zeros((d,d))
            for j in range(n):
                cov[i][0] = cov[i][0] + w[i,j] * (D[j,:] - mu[i,:]) @ (D[j,:] - mu[i,:]).T
            cov[i][0] = cov[i][0] / np.sum(w[i,:],axis=0)

            # Re-estimate priors
            priors[i] = np.sum(w[i,:],axis=0) / n

        # Check for convergence
        if np.linalg.norm(mu - prev_mu) ** 2 <= eps:
            # Clusters as list of k lists
            C = [[] for i in range(k)]
            labels = [[] for i in range(k)]

            # Cluster assignment step
            for i in range(n):
                max_prob = sys.float_info.min
                max_idx = -1
                # Get probability of x_i (D[i,:]) being generated by each cluster
                for j in range(k):
                    prob = f(D[i,:],mu[j,:],cov[j][0])
                    if prob > max_prob:
                        max_prob = prob
                        max_idx = j
                # Add data point to cluster that most likely generated it
                C[max_idx].append(D[i,:])
                labels[max_idx].append(i+1)

            return C, labels, mu, cov, priors, iter

        # Update iteration count
        iter += 1
        # Update previous mu
        prev_mu = np.copy(mu)


# Multivariate normal distribution helper function
def f(x,mu,cov):
    return 1. / (((2*np.pi) ** (float(cov.shape[0])/2)) * (np.linalg.det(cov) ** (1./2))) * np.exp(-(1./2) * (x-mu).T @ np.linalg.inv(cov) @ (x-mu))

# Sum of squared error helper function
def SSE(C, mu):
    sse = 0
    for c_i in C:
        sse = sse + np.linalg.norm(c_i - mu) ** 2
    return sse






# Get the arguments list 
argv = str(sys.argv)
print(str(argv))

# Get number of arguments
argc = len(sys.argv)

# Print error if not enough arguments
if argc < 3:
    sys.exit("Datafile and k arguments are required!")

# Read in D data matrix
if sys.argv[1] == "iris.data.txt" or sys.argv[1] == "iris.txt":
    D = np.loadtxt(sys.argv[1],delimiter=',',usecols=(0,1,2,3))
else:
    D = np.loadtxt(sys.argv[1],delimiter=',')
if len(D.shape) < 2:
    D = D.reshape((D.shape[0],1))

# Read in k cluster count
k = int(sys.argv[2])

# Read in mu mean matrix if given
mu = np.zeros((k,D.shape[1]))
if argc > 3:
    mu = np.loadtxt(sys.argv[3],delimiter=',')
    if len(mu.shape) < 2:
        mu = mu.reshape((mu.shape[0],1))

C, labels, mu, cov, priors, iter = EM(D, k, mu)
total_sse = 0

# Print input information
n, d = D.shape
print("Number of Datapoints: n=" + str(n))
print("Number of Dimensions: d=" + str(d))
print("Number of Clusters: k=" + str(k))
print("\n")

# Print results
print("Convergence after " + str(iter) + " iterations:")
for i in range(k):
    print("-----Cluster " + str(i) + "---------------")
    print(str(len(C[i])) + " elements:" + str(labels[i]))
    print("mu_" + str(i) + ": " + str(mu[i,:]))
    print("cov_" + str(i) + ": " + str(cov[i][0]))
    print("prior_" + str(i) + ": " + str(priors[i]))
    print("SSE_" + str(i) + ": " + str(SSE(C[i],mu[i,:])))
    total_sse = total_sse + SSE(C[i],mu[i,:])
print("\n")
print("Total SSE: " + str(total_sse))